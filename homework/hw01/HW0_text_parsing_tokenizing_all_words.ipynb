{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "397d2f9f-881f-4a23-87bd-5009b69b7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "af4dc99f-2aa9-4400-8485-ec9271c426c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check lower case and upper case. have used code given by professor\n",
    "pat_lower = re.compile(r'[a-z]+\\'?[a-z]*')\n",
    "pat_upper = re.compile(r'[A-Z]+\\'?[a-z]*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8a4ae-4f6a-4f9a-b39d-e79c06d42986",
   "metadata": {},
   "source": [
    "In the below code, I have tried to include the words containing apostrophe but few words are still missing like God's and Bakeley's. I have tried different ways but these words were directly removing punctuations. Will try further on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "643ab52b-e4fb-45ed-9055-26c0f15f2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(s):\n",
    "    # Processing the string based on its case\n",
    "    m_lower = pat_lower.match(s)\n",
    "    m_upper = pat_upper.match(s)\n",
    "    \n",
    "    # For lowercase words\n",
    "    if m_lower:\n",
    "        processed_word = m_lower.group(0).lower()\n",
    "        # Removing punctuation at the end of the word\n",
    "        processed_word = processed_word.strip(string.punctuation)\n",
    "        return processed_word\n",
    "    # For uppercase words\n",
    "    elif m_upper:\n",
    "        processed_word = m_upper.group(0).lower() #as it is all words making them lower case\n",
    "        if processed_word.endswith(\"'s\") and len(processed_word) > 2:\n",
    "            # Retain the entire word with \"'s\" in lowercase\n",
    "            return processed_word\n",
    "        else:\n",
    "            # Remove punctuation at the end of the word\n",
    "            processed_word = processed_word.strip(string.punctuation)\n",
    "        return processed_word\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b89ff777-5170-4b60-8044-e91331e8a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here using counter to count the frequency of the word\n",
    "def tokenize_and_count_words(text):\n",
    "    words = text.split()\n",
    "    word_counts = Counter()\n",
    "\n",
    "    for word in words:\n",
    "        processed_word = process_string(word)\n",
    "        if processed_word:\n",
    "            word_counts[processed_word] += 1\n",
    "\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "26858cd2-f70f-4ea0-918e-f55307c29241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text from the input file\n",
    "input_file_path = 'pg5827.txt'\n",
    "with open(input_file_path, 'r') as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b78d94b3-4564-4f28-88cb-90e6a24ce72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize and count the words frequency\n",
    "word_counts = tokenize_and_count_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0bf44823-4c04-4bcd-82f0-460f7ebd9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'all_words.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "256fd761-d4da-4006-bf36-ed229033b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the word counts alphabetically by word\n",
    "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "70de0eb1-9585-465a-92b7-1f60040ec69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing them to new file all_words.csv \n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['word', 'count']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for word, count in sorted_word_counts:\n",
    "        writer.writerow({'word': word, 'count': count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f2c2172b-cba2-4ae2-8d78-d4e9b3a9b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts saved to all_words.csv\n"
     ]
    }
   ],
   "source": [
    "print('Word counts saved to', output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "df126624-e04a-406e-b95e-a7cac090c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d23d9cac-3a74-4809-a46c-db4e90339c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9ed5f6f8-9503-4099-a750-47be065ec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the data assiging the all_words.csv to df\n",
    "csv_file_path = 'all_words.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b91bf9e7-1936-4c14-abd5-474ef61c1b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>able</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>about</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  count\n",
       "0        a    831\n",
       "1  abandon      2\n",
       "2    abide      1\n",
       "3     able     13\n",
       "4    about     90"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fc33e821-8183-4d55-8acb-8075a550100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_apostrophe = df[df['word'].str.contains(\"'\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ccfbf157-7b1d-4e6e-a3b8-5b499bdfc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with an apostrophe:\n",
      "               word  count\n",
      "173       anybody's      1\n",
      "410             c's      1\n",
      "980         earth's      2\n",
      "1283       friend's      2\n",
      "1475            i's      2\n",
      "1824          man's     11\n",
      "1861          men's      1\n",
      "1889         mind's      2\n",
      "2181       people's      8\n",
      "2219  philosopher's      1\n",
      "2767     somebody's      1\n",
      "2891          sun's      1\n",
      "2980        thing's      3\n"
     ]
    }
   ],
   "source": [
    "#here we can see that for many words punctuation logic worked well\n",
    "print(\"Words with an apostrophe:\")\n",
    "print(words_with_apostrophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c8def156-ef56-4ce7-862a-8f23929c4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by word count in descending order\n",
    "sorted_df = df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "74133996-2e0f-48d5-941d-308f41d74a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_words = sorted_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d386abe7-f298-4d50-bb6d-c21c853e9c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most frequent words:\n",
      "     word  count\n",
      "2963  the   2700\n",
      "2065   of   1883\n",
      "1664   is   1322\n",
      "3006   to   1268\n",
      "154   and   1008\n"
     ]
    }
   ],
   "source": [
    "#here we can see the top 5 frequent words\n",
    "print('The 5 most frequent words:')\n",
    "print(top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064ca29-13b8-4d9b-ada4-df90bd0c8e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
